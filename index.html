<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Valerie Chen</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101241284);</script>
    <script async src="//static.getclicky.com/js"></script>
</head>
<body>
    <!-- Top Banner with Navigation Links -->
    <header class="banner">
        <nav class="navbar">
            <a href="index.html" class="nav-link">Home</a>
            <a href="full_pubs.html" class="nav-link">Publications</a>
            <a href="teaching.html" class="nav-link">Teaching & Mentorship</a>
            <a href="talks.html" class="nav-link">Service</a>
        </nav>
    </header>

    <!-- Intro Section -->
    <section id="intro" class="intro-container">
        <div class="profile-photo">
            <img src="images/headshot1.png" alt="Profile Picture">
        </div>
        <div class="intro-text">
            <h1>Valerie Chen</h1>
            <p>Carnegie Mellon University <br> Machine Learning Department</p>
            <div class="social-icons">
                <a href="https://scholar.google.com/citations?user=94yn2j0AAAAJ&hl=en" target="_blank" aria-label="Google Scholar"><i class="fab fa-google"></i></a>
                <a href="https://x.com/valeriechen_" target="_blank" aria-label="Twitter"><i class="fab fa-twitter"></i></a>
                <a href="https://github.com/valeriechen" target="_blank" aria-label="GitHub"><i class="fab fa-github"></i></a>
                <a href="mailto:valeriechen@cmu.edu" aria-label="Email"><i class="fas fa-envelope"></i></a>
            </div>
        </div>

    </section>

    <!-- Brief Intro Paragraph -->
    <section id="about" class="section">
        <h2>About Me</h2>
        <p> I'm a final year <a href="https://www.ml.cmu.edu/"> Machine Learning</a> PhD student at Carnegie Mellon University advised by <a href="https://www.cs.cmu.edu/~atalwalk/"> Ameet Talwalkar</a>. I also spend time at <a href="https://www.all-hands.dev/">OpenHands</a> working with <a href="https://www.phontron.com/">Graham Neubig</a>.</p>

        <p>As AI systems become deeply embedded in human work, <strong>my research focuses on building AI co-workers that collaborate effectively with people.</strong> I work at the intersection of ML, NLP, and HCI on:</p>

        <ul class="research-points">
            <li>
            <em>Measuring</em> collaborative capabilities of AI systems
              (<a href="https://openreview.net/forum?id=9bYOqwtAud" class="paper-link">Copilot Arena</a>, <a href="https://arxiv.org/abs/2510.25744" class="paper-link">Collaborative Effort Scaling</a>).
            </li>
            <li>
            <em>
              Learning</em> from human feedback and interactions with collaborative AI
              (<a href="https://arxiv.org/abs/2510.09801" class="paper-link">PULSE</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33555" class="paper-link">Modiste</a>).
            </li>
            <li>
            <em>
              Optimizing</em> interfaces to improve human productivity and decision-making
              (<a href="https://dl.acm.org/doi/full/10.1145/3706598.3714002" class="paper-link">Proactive AI</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3610219" class="paper-link">Interpretability</a>).
            </li>
            <!-- Add future of work: BNY, Code with me or for me -->
            <!-- <li>
            <em>
              Real-world deployments</em> to study how AI co-workers shape work practices
              (<a href="https://arxiv.org/abs/2502.09328" class="paper-link">Copilot Arena</a>, <a href="https://openreview.net/pdf?id=9bYOqwtAud" class="paper-link">AI-assisted decision-making</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/30082" class="paper-link">AI-assisted coding</a>).
            </li>    -->
        <!-- <li>
          <em>
            Developing algorithmic frameworks and evaluation paradigms</em> that integrate state-of-the-art models and interactive agents into collaborative settings
            [<a href="https://arxiv.org/abs/2510.09801" class="paper-link">1</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33555" class="paper-link">2</a>, <a href="https://openreview.net/pdf?id=48Js-sP8wnv" class="paper-link">3</a>].
          
        </li>
        <li>
          <em>
            Partnering with industry organizations</em> to study how these systems shape work practices 
            and decision-making in real-world contexts
            [<a href="https://openreview.net/pdf?id=9bYOqwtAud" class="paper-link">4</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/30082" class="paper-link">5</a>, <a href="https://openreview.net/pdf/4add16809c3aba8bf141fdf5762eeec138c07070.pdf" class="paper-link">6</a>].
          
        </li>
        <li>
          <em>
            Contributing behavioral insights into human‚ÄìAI interactions</em> to inform the design 
            of next-generation AI co-workers
            [<a href=" https://dl.acm.org/doi/abs/10.1145/3610219" class="paper-link">7</a>, <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00685/124261" class="paper-link">8</a>, <a href="https://dl.acm.org/doi/full/10.1145/3706598.3714002" class="paper-link">9</a>].
        </li> -->
      </ul>

        <p><strong>Impact:</strong> My work has been recognized by the <a href="https://datascience.ucsd.edu/rising-stars-in-data-science/">Rising Stars in Data Science award</a>, <a href="https://www.cmu.edu/ini/admissions/financial/scholarship.html">CMU Presidential Fellowship</a>, and <a href="https://www.research.gov/grfp/AwardeeList.do">NSF Graduate Research Fellowship</a>. My research has fostered close collaborations with major international companies in engineering and financial sectors, including JetBrains, Feedzai, and BNY Mellon, and have been cited in releases by leading model providers like Mistral, InceptionAI, and Qwen. My research has also received various awards, including Best Paper at a NeurIPS workshop and Oral Presentations at ICLR and AAAI.</p>


        <p>During my PhD, I was a visiting researcher at NYU with <a href="https://hhexiy.github.io/">He He</a> and intern at Microsoft Research with <a href="http://www.qveraliao.com/">Q. Vera Liao</a> and <a href="http://www.jennwv.com/">Jennifer Wortman Vaughan</a>. I completed my BS in Computer Science at Yale University.</p>

    </section>

    <!-- News Section -->
    <section id="news" class="section">
        <h2>Recent News</h2>
        <ul>
            <li> üì¢ I'm on the academic job market! Please reach out if I might be a good fit. üì¢</li>
            <li>Dec 2025: Our work on <a href="https://arxiv.org/abs/2510.09801">Collaborative Effort Scaling</a> won <span style="color: blue; font-weight: bold;">Best Paper</span> at NeurIPS Responsible Foundation Models Workshop! üèÜ</li>
            <li>Nov 2025: Gave guest lectures in 3 CMU classes about human-centered design of coding agents. <a href="https://docs.google.com/presentation/d/1mZcePXJ-cAjQ8PrWsseswbDa7tScSYAw/edit?usp=sharing&ouid=103824579810541476593&rtpof=true&sd=true">[slides]</a></li>
            <li>Oct 2025: Selected as a top reviewer of NeurIPS 2025!</li>
            <li>Sep 2025: Co-organized CMU NSF AI-SDM's workshop on Human-AI Complementarity <a href="https://www.cmu.edu/ai-sdm/research/human-ai-workshop/index.html">[link]</a></li>
            <li>Jun 2025: Started my internship at OpenHands üôå</li>
            <li>May 2025: This summer I'll be presenting accepted work at CHIüáØüáµ, FSEüá≥üá¥, and ICMLüá®üá¶.</li>
          </ul> 
    </section>

    <!-- <section id="recent-pub" class="section">
        <h2>Research Directions</h2>

        <p>See the full list of publications <a href="full_pubs.html" rel="noopener noreferrer">here</a>.</p>

        <strong> Scaling Measurements of Collaborative Capabilities.</strong> AI progress has traditionally been benchmarked through static tasks that abstract away the complexities of human‚ÄìAI interaction. I develop algorithmic frameworks that reliably measure interaction with users at scale.

        <details>
           <summary style="margin-left: 1rem; color: #666;">Read more</summary>
              <ul style="margin-left: 2rem; color: #666;"></ul>
            <ul>
                <li> I co-created Copilot Arena, a platform that integrates preference collection directly into developers‚Äô working environments.
                    Copilot Arena has served over 10 million suggestions from over 20 models and collected over 30k pairwise judgements, enabling insights that are only possible at this scale. 
                    Copilot Arena was used to evaluate pre-released versions of multiple coding models and was featured in the Wall Street Journal.
                </li>
                <li>To rigorously and efficiently evaluate agent designs, we introduce PULSE, which trains an ML model to predict user satisfaction and compues results by combining human satisfaction ratings with model-generated pseudo-labels using statistical inference techniques.
                    I collaborated with OpenHands to deploy the framework at scale and collect in-the-wild usage data across over 15k users and XXk trajectories.
                    The first work to... 
                </li>
            </ul>
        </details>

        <br>

        <strong> LLMs as Human Proxies for Design Space Exploration.</strong> To enable more systematic coverage of the design space beyond what is feasible with a sampled user population, a complementary direction is employing simulated users powered by ML models or LLMs to approximate human decisions.
        <details>
           <summary style="margin-left: 1rem; color: #666;">Read more</summary>
              <ul style="margin-left: 2rem; color: #666;"></ul>
            <ul>
                <li> I co-created Copilot Arena, a platform that integrates preference collection directly into developers‚Äô working environments.
                    Copilot Arena has served over 10 million suggestions from over 20 models and collected over 30k pairwise judgements, enabling insights that are only possible at this scale. 
                    Copilot Arena was used to evaluate pre-released versions of multiple coding models and was featured in the Wall Street Journal.
                </li>
                <li>To rigorously and efficiently evaluate agent designs, we introduce PULSE, which comprises collecting user feedback, training an ML model to predict user satisfaction, and computing results by combining human satisfaction ratings with model-generated pseudo-labels using statistical inference techniques.
                    I collaborated with OpenHands to deploy the framework at scale and collect in-the-wild usage data across over 15k users. 
                </li>
            </ul>
        </details>

         <br>

        <strong> Scaling Measurements of Collaborative Capabilities.</strong> AI progress has traditionally been benchmarked through canonical tasks such as chess, standardized exams, and programming contests. These evaluations abstract away the complexities of human‚ÄìAI interaction
        <details>
            <summary style="margin-left: 1rem; color: #666;">Read more</summary>
              <ul style="margin-left: 2rem; color: #666;"></ul>
              <ul>
            <li> I co-created Copilot Arena, a platform that integrates preference collection directly into developers‚Äô working environments.
                Copilot Arena has served over 10 million suggestions from over 20 models and collected over 30k pairwise judgements, enabling insights that are only possible at this scale. 
                Copilot Arena was used to evaluate pre-released versions of multiple coding models and was featured in the Wall Street Journal.
            </li>
            <li>To rigorously and efficiently evaluate agent designs, we introduce PULSE, which comprises collecting user feedback, training an ML model to predict user satisfaction, and computing results by combining human satisfaction ratings with model-generated pseudo-labels using statistical inference techniques.
                I collaborated with OpenHands to deploy the framework at scale and collect in-the-wild usage data across over 15k users. 
            </li>
            <li>

            </li>
          </ul> 
        </details>

    </section>
     -->

    <!-- Recent Publications -->
    <section id="recent-pub" class="section">
        <h2>Selected Recent Publications</h2>

        <p>See the full list of publications <a href="full_pubs.html" rel="noopener noreferrer">here</a>.</p>

        <a href="http://arxiv.org/abs/2502.09328">Copilot Arena: A Platform for Code LLM Evaluation in the Wild</a>
              <br>
              Wayne Chi*, <strong>Valerie Chen*</strong>, Anastasios Nikolas Angelopoulos, Wei-Lin Chiang, Aditya Mittal, Naman Jain, Tianjun Zhang, Ion Stoica, Chris Donahue, Ameet Talwalkar
              <br>
              <em>ICML, 2025</em>
              <br><br>

              <a href="https://dl.acm.org/doi/10.1145/3706598.3714002">Need Help? Designing Proactive AI Assistants for Programming</a>
              <br>
              <strong>Valerie Chen</strong>, Alan Zhu, Sebastian Zhao, Hussein Mozannar, David Sontag, Ameet Talwalkar
              <br>
              <em>CHI, 2025</em>
              <br><br>

              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33555">Learning Personalized Decision Support Policies</a>
              <br>
              Umang Bhatt*, <strong>Valerie Chen*</strong>, Katie Collins, 
              Parameswaran Kamalaruban, Emma Kallina, Adrian Weller, Ameet Talwalkar
              <br>
              <em>AAAI, 2025</em>
              <br><br>

              <a href="https://openreview.net/forum?id=hGaWq5Buj7">The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers</a>
              <br>
              Hussein Mozannar*, <strong>Valerie Chen*</strong>, Mohammed Alsobay, Subhro Das, Sebastian Zhao, Dennis Wei, Manish Nagireddy, Prasanna Sattigeri, Ameet Talwalkar, David Sontag
              <br>
              <em>TMLR, 2025</em>

    </section>
    