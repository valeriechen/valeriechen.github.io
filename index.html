<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Valerie Chen</title>
  
  <meta name="author" content="Valerie Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101241284);</script>
  <script async src="//static.getclicky.com/js"></script>
  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

    <tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <p style="text-align:center">
                <name>Valerie Chen</name>
              </p>

          <img style="width:25%;max-width:25%" alt="profile photo" src="images/headshot.png" class="center">

          <tr>
            <td>

        <p> I'm a fourth year <a href="https://www.ml.cmu.edu/"> Machine Learning</a> PhD student at Carnegie Mellon University advised by <a href="https://www.cs.cmu.edu/~atalwalk/"> Ameet Talwalkar</a> and my PhD is supported by the NSF Graduate Research Fellowship. I previously interned at Microsoft Research in the <a href="https://www.microsoft.com/en-us/research/theme/fate/">FATE (Fairness, Accountability, Transparency, and Ethics of AI)</a> group with <a href="http://www.qveraliao.com/">Q. Vera Liao</a> and <a href="http://www.jennwv.com/">Jennifer Wortman Vaughan</a>. I completed my BS in Computer Science at Yale University, where I previously worked with <a href="https://www.cs.yale.edu/homes/shao-zhong/"> Zhong Shao</a> and <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>. I have also spent time at IBM Research and the Naval Research Laboratory. </p>

          

              <p style="text-align:center">
                <a href="mailto:valeriechen@cmu.edu">Email</a> /
                <a href="https://scholar.google.com/citations?user=94yn2j0AAAAJ&hl=en">Google Scholar</a> / <a href="https://twitter.com/valeriechen_"> Twitter </a>
                <!-- <a href="https://www.linkedin.com/in/valeriechen11/"> LinkedIn </a> /
                <a href="https://github.com/valeriechen"> Github </a> -->
              </p>
          </td>
          </tr>

        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>

              <center><heading>Current research interests</heading></center><br>

              My research focuses on building tools and theory to improve <b>human-AI interactions</b>, more recently focusing on human interactions with LLMs. Below are selected work on three topics that I am actively working on (<a href="https://scholar.google.com/citations?user=94yn2j0AAAAJ&hl=en">full list here</a>).

              

              <u><h3>Understanding human-AI interactions</h3> </u>

              <a href="https://arxiv.org/abs/2206.13503">On the Importance of Application-Grounded Experimental Design for Evaluating Explainable ML Methods</a>
              <br>
              Kasun Amarasinghe, Kit Rodolfa, Sergio Jesus, <strong>Valerie Chen</strong>, Vladimir Balayan, Pedro Saleiro, Pedro Bizarro, Ameet Talwalkar, Rayid Ghani
              <br>
              <em>AAAI (Special Track on Safe, Robust and Responsible AI), 2024</em>
              <br><br>


              <a href="https://dl.acm.org/doi/10.1145/3610219">Understanding the Role of Human Intuition on Reliance in Human-AI Decision-Making with Explanations</a>
              <br>
              <strong>Valerie Chen</strong>,
              Q. Vera Liao, Jennifer Wortman Vaughan, Gagan Bansal
              <br>
              <em>CSCW, 2023</em>
              <br><br>


              <a href="https://openreview.net/forum?id=5rq8iRzHAQ">Assisting Human Decisions in Document Matching</a>
              <br>
              Joon Sik Kim, <strong>Valerie Chen</strong>,
              Danish Pruthi, Nihar Shah, Ameet Talwalkar
              <br>
              <em>TMLR, 2023</em>
              <br><br>



              <a href="https://dl.acm.org/doi/10.1145/3511299">Interpretable Machine Learning: Moving From Mythos to Diagnostics</a>
              <br>
              <strong>Valerie Chen*</strong>,
              Jeffrey Li*,
              Joon Sik Kim**,
              Gregory Plumb**,
              Ameet Talwalkar
              <br>
              <!-- <em>ICML HILL Workshop, 2021</em>
              <br>
              <em>ACM Queue, 2022 </em>
              <br> -->
              <em>Communications of ACM, 2022</em>
              <br><br>


               <u><h3>Improving human-AI interaction by incorporating user {expertise, preference, prior}</h3> </u>

            
              <a href="https://dl.acm.org/doi/10.1145/3617694.3623239">FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines</a>
              <br>
              Matthew Barker, Emma Kallina, Dhananjay Ashok, Katherine Collins, Ashley Casovan, Adrian Weller, Ameet Talwalkar, <strong>Valerie Chen*</strong>, Umang Bhatt*
              <br>
              <em>EAAMO, 2023</em>
              <br><br>


              <a href="https://arxiv.org/abs/2304.06701">Learning Personalized Decision Support Policies</a>
              <br>
              Umang Bhatt*, <strong>Valerie Chen*</strong>, Katie Collins, 
              Parameswaran Kamalaruban, Emma Kallina, Adrian Weller, Ameet Talwalkar
              <br>
              Preprint
              <br><br>



              <a href="https://www.cell.com/patterns/fulltext/S2666-3899(23)00131-9">Perspectives on Incorporating Expert Feedback into Model Updates</a>
              <br>
              <strong>Valerie Chen*</strong>,
              Umang Bhatt*, Hoda Heidari, Adrian Weller, Ameet Talwalkar
              <br>
              <em>Patterns, 2023</em>
              <br><br>


              <a href="https://openreview.net/pdf?id=Z6BFQqzwuS4">Bayesian Persuasion for Algorithmic Recourse</a>
              <br>
              Keegan Harris,
              <strong>Valerie Chen</strong>,
              Joon Sik Kim, Ameet Talwalkar, Hoda Heidari, Steven Wu
              <br>
              <em>NeurIPS, 2022</em>
              <br><br>


               <u><h3> Evaluating Human-AI interaction by simulating human behaviors </h3></u>


              <a href="https://openreview.net/forum?id=0nRcZeeE5f">Simulating Iterative Human-AI Interaction in Programming with LLMs</a>
              <br>
              Hussein Mozannar*, <strong>Valerie Chen*</strong>, Dennis Wei, Prasanna Sattigeri, Manish Nagireddy, Subhro Das, Ameet Talwalkar, David Sontag
              <br>
              <em>Neurips Workshop on Instruction Tuning and Instruction Following, 2023</em> 
              <br><br>


              <a href="https://arxiv.org/abs/2311.04076">Do LLMs exhibit human-like response biases? A case study in survey design</a>
              <br>
              Lindia Tjuatja*, <strong>Valerie Chen*</strong>,
              Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig
              <br>
              <em>CMU LTI Student Research Symposium, 2023</em> (Best Preliminary Paper Award)
              <br><br>

              <a href="https://arxiv.org/abs/2302.07444">A Case Study on Designing Evaluations of ML Explanations with Simulated User Studies</a>
              <br>
              Ada Martin, <strong>Valerie Chen</strong>,
              Sergio Jesus, Pedro Saleiro
              <br>
              <em>ICLR Workshop on Trustworthy ML, 2023</em>
              <br><br>

              <a href="https://openreview.net/pdf?id=48Js-sP8wnv">Use-Case-Grounded Simulations for Explanation Evaluation</a>
              <br>
              <strong>Valerie Chen</strong>,
              Nari Johnson, Nicholay Topin*, Gregory Plumb*, Ameet Talwalkar
              <br>
              <em>NeurIPS, 2022</em>
              <!-- <em>NeurIPS XAI4Debugging Workshop, 2021</em> -->
              <br><br>



            </td>
          </tr>
        </tbody></table>




        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <center><heading>Important non-research things</heading></center>
              <br><br>
              DEI Course at CMU (<a href="https://www.cs.cmu.edu/~15996/"> check out the course website </a>) 
              <br><br>
              Yale Women's Leadership Initiative (<a href="https://www.yalewli.org/">support remembering 50 at Yale here </a>)
              <br><br>
              SheCode at Yale (<a href="https://shecodeatyale.wordpress.com/"> org website</a>)
              <br><br>
              Computation and Society at Yale (<a href="https://computationsociety.yale.edu/"> yalies should get involved here </a>)
              <br>
            </td>
          </tr>
        </tbody></table>


      </td>
    </tr>


  </table>


</body>

</html>
